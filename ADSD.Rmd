---
title: "ADSD"
author: "Simon Schwab"
date: "07 Nov 2017"
output: html_notebook
---

## Install packages
```{r Install packages}
# install.packages("rmarkdown")
# install.packages("testit")
# install.packages("reshape2")
# install.packages("ggplot2")
# install.packages("cowplot")
# install.packages("Hmisc")
# install.packages("nortest")
# install.packages("multdyn")
# install.packages("perm")
# install.packages("lme4")
# install.packages("moments")
```

## Load libraries
```{r Load libraries, message=FALSE, warning=TRUE}
library(testit)
library(reshape2)
library(ggplot2)
library(cowplot)
library(Hmisc) # for rcor
library(nortest)
library(lme4)
library(multdyn)
library(moments)
library(perm)
```

## Main variables
```{r Main variables}
N = 62
N_ROIS = 200
PATH_HOME = "/home/simon"
PATH_ROIS200 = file.path(PATH_HOME, 'Drive', 'ADSD_200ROIS_N62')
PATH_ROIS200_GSR = file.path(PATH_HOME, 'Drive', 'ADSD_200ROIS_GSR_N62')
PATH_ROIS200_GSR_AR1 = file.path(PATH_HOME, 'Drive', 'ADSD_200ROIS_GSR_AR1_N62')
PATH = file.path(PATH_HOME, 'Data', 'ADSD')
```

## Subject infos
```{r Subjects infos}
infos = read.table(file.path(PATH, 'ADSD_info.txt'), header = T)
#rois = read.table(file.path(PATH, 'ROIs_14.txt'), header = T)
# Excluded subjects
infos$included = rep(TRUE,N)
# DVARS; more than 20% volumes affected:
infos$included[match("ADSD_13", infos$id)] = FALSE
infos$included[match("ADSD_36", infos$id)] = FALSE
# High E-vars:
infos$included[match("ADSD_34", infos$id)] = FALSE
# DVARS below 40%:
infos$included[match("ADSD_15", infos$id)] = FALSE
infos$included[match("ADSD_42", infos$id)] = FALSE
infos$included[match("ADSD_43", infos$id)] = FALSE

infos$included[match("2026", infos$id)] = FALSE # no mri data

infos$isHC = as.logical(infos$isHC)
infos$isAD = as.logical(infos$isAD)
infos$isSD = as.logical(infos$isSD)

infos$group=rep(NA, N)
infos$group[infos$isSD] = 'SD'
infos$group[infos$isAD] = 'AD'
infos$group[infos$isHC] = 'HC'
infos$group = as.factor(infos$group)

assert(nrow(infos) == N)
N_SD  = sum(infos$isSD & infos$included)
N_AD  = sum(infos$isAD & infos$included)
N_HC  = sum(infos$isHC & infos$included)

# DVARS
dvars=read.table(file.path(PATH, 'DVARS.txt'), header = T)
assert(nrow(dvars) == nrow(infos))
infos = cbind(infos, dvars)
rm(dvars)

print(infos)
```
## Demographics
```{r Demographics}
d.demog = data.frame(Group=as.factor(c('SD', 'AD', 'HC')),
                     N_Total=c(sum(infos$isSD), sum(infos$isAD), sum(infos$isHC)),
                     N_included=c(sum(infos$isSD & infos$included), sum(infos$isAD & infos$included),
                                  sum(infos$isHC & infos$included)),
                     age_mean=round(c(mean(infos$age[infos$isSD & infos$included]),
                                 mean(infos$age[infos$isAD & infos$included]),
                                 mean(infos$age[infos$isHC & infos$included]))),
                     age_sd=round(c(sd(infos$age[infos$isSD & infos$included]),
                                    sd(infos$age[infos$isAD & infos$included]),
                                    sd(infos$age[infos$isHC & infos$included])))
)

print(d.demog)
```

## DVARS analysis
```{r}
a = read.table(file.path(PATH, 'DVARS_vols_affected.txt'), header = F)
b = cbind(rep(0,N), a[,1:ncol(a)-1])
affected = a | b
rm(a); rm(b)

# which subjetc have more than 20% of their volumes affected?
print(as.character(infos$id[rowSums(affected) > infos$N_vols*0.2]))

# lillie.test(infos$SD_SDVARS_X2)
kruskal.test(SD_SDVARS_X2 ~ group, data=infos)

# lillie.test(infos$g_Avar)
kruskal.test(g_Avar ~ group, data=infos)

# DVARS after excluding subjects
infos_ = subset(infos, included)

kruskal.test(SD_SDVARS_X2 ~ group, data=infos_)
kruskal.test(g_Avar ~ group, data=infos_)
```
### Plot
```{r, fig.height=2, fig.width=4}
x=infos$Svar/infos$Dvar
p1 = ggplot(infos, aes(x=group, y=Svar/Dvar)) + geom_boxplot() + 
  coord_cartesian(ylim = c(0.5,2), expand = TRUE) +
  ggtitle(paste("N =", as.character(dim(infos)[1])))

p2 = ggplot(infos_, aes(x=group,y=Svar/Dvar)) + geom_boxplot() + 
  coord_cartesian(ylim = c(0.5,2), expand = TRUE) +
  ggtitle(paste("N =", as.character(dim(infos_)[1])))

plot_grid(p1, p2, ncol = 2, nrow = 1, rel_widths = c(1, 1))
```


### Plot
```{r, fig.height=4, fig.width=4}
set.seed(1980)
p1 = ggplot(infos, aes(x=group, y=SD_SDVARS_X2)) + geom_boxplot() + 
  coord_cartesian(ylim = c(0.8, 2)) +
  geom_point(shape=1, color="gray70", size=2, position = position_jitter(width = 0.2, height = 0.01)) +
  ggtitle("before exclusion")

p2 = ggplot(infos_, aes(x=group, y=SD_SDVARS_X2)) + geom_boxplot() +
  coord_cartesian(ylim = c(0.8, 2)) +
  geom_point(shape=1, color="gray70", size=2, position = position_jitter(width = 0.2, height = 0.01)) + 
  ggtitle("after exclusion")

p3 = ggplot(infos, aes(x=group, y=g_Avar)) + geom_boxplot() +
  geom_point(shape=1, color="gray70", size=2, position = position_jitter(width = 0.2, height = 0.01)) +
  ggtitle("before exclusion")

p4 = ggplot(infos_, aes(x=group, y=g_Avar)) + geom_boxplot() +
  geom_point(shape=1, color="gray70", size=2, position = position_jitter(width = 0.2, height = 0.01)) + 
  ggtitle("after exclusion")

plot_grid(p1, p2, p3, p4, ncol = 2, nrow = 2, rel_widths = c(1, 1))
```


## Global signal regression
```{r, warning=FALSE}
# # first stockholm sample, then china sample
# f1 = list.files(path = PATH_ROIS200, pattern = "^ADSD.*.txt")
# f2 = list.files(path = PATH_ROIS200, pattern = "^20.*.txt")
# f = c(f1,f2)
# rm(f1); rm(f2)
# assert(length(f) == N)
# 
# for (s in 1:N) {
#   d = read.table(file.path(PATH_ROIS200, f[s]), header = F)
#   # acf(d[,50]) # check autocorrelation
#   idx = !affected[s,][1:infos$N_vols[s]]
#   d = as.matrix(d[idx,]) # excluding affected scans
# 
#   # global signal regression
#   d_gs = array(NA, dim=dim(d))
#   gs = apply(d, 1, mean, na.rm=T)
#   for (r in 1:N_ROIS) {
#     if (sum(is.na(d[,r])) == length(gs)) {
#       d_gs[,r] = rep(NA, length(gs))
#     } else {
#       fit = lm(d[,r] ~ gs)
#       d_gs[,r] = fit$residuals
#     }
#   }
# 
#   # save gs time series
#   write(t(d_gs), file=file.path(PATH_ROIS200_GSR, f[s]), ncolumns = N_ROIS)
# }
```

## Load time series
```{r warning=FALSE}
# # first stockholm sample, then china sample
# f1 = list.files(path = PATH_ROIS200, pattern = "^ADSD.*.txt")
# f2 = list.files(path = PATH_ROIS200, pattern = "^20.*.txt")
# f = c(f1,f2)
# rm(f1); rm(f2)
# assert(length(f) == N)
# 
# R = R_gsr = R_ar1 = array(NA, dim=c(N_ROIS, N_ROIS, N))
# P_ar1 = array(NA, dim=c(N_ROIS, N_ROIS, N))
# for (s in 1:N) {
#   
#   d = as.matrix(read.table(file.path(PATH_ROIS200, f[s]), header = F))
#   #acf(d[,50]) # check autocorrelation
#   tmp =  rcorr(d, type="pearson")
#   R[,,s] = tmp$r
#   
#   d = as.matrix(read.table(file.path(PATH_ROIS200_GSR, f[s]), header = F))
#   tmp =  rcorr(d, type="pearson")
#   R_gsr[,,s] = tmp$r
#   
#   d = as.matrix(read.table(file.path(PATH_ROIS200_GSR_AR1, f[s]), header = F))
#   tmp =  rcorr(d, type="pearson")
#   R_ar1[,,s] = tmp$r
#   P_ar1[,,s] = tmp$P
# }
# save(R, R_gsr, R_ar1, P_ar1, file = file.path(PATH, 'ADSD.RData'))

load(file.path(PATH, 'ADSD.RData'))
```

### Compare distributions of Pearson's r
```{r}
g = c(rep('SD', N_ROIS*N_ROIS*sum(infos$isSD)),
      rep('AD', N_ROIS*N_ROIS*sum(infos$isAD)),
      rep('HC', N_ROIS*N_ROIS*sum(infos$isHC))
)


Rd = data.frame(R = c(c(R[,,infos$isSD]), c(R[,,infos$isAD]), c(R[,,infos$isHC])), group = g)
Rd$group = factor(Rd$group, levels = c("HC", "SD", "AD"))

Rd_gsr = data.frame(R = c(c(R_gsr[,,infos$isSD]), c(R_gsr[,,infos$isAD]), c(R_gsr[,,infos$isHC])), group = g)
Rd_gsr$group = factor(Rd_gsr$group, levels = c("SD", "HC", "AD"))

Rd_ar1 = data.frame(R = c(c(R_ar1[,,infos$isSD]), c(R_ar1[,,infos$isAD]), c(R_ar1[,,infos$isHC])), group = g)
Rd_ar1$group = factor(Rd_ar1$group, levels = c("AD", "HC", "SD"))

s = c(rep('Sweden', N_ROIS*N_ROIS*sum(infos$site==1)),
      rep('China',  N_ROIS*N_ROIS*sum(infos$site==2))
)

Rd_site = data.frame(R = c(c(R_ar1[,,infos$site==1]), c(R_ar1[,,infos$site==2])), site = s)
Rd_site$site = factor(Rd_site$site, levels = c("Sweden", "China"))

M = array(c(
  mean(R_ar1[,,infos$isSD], na.rm = T), mean(R_ar1[,,infos$isAD], na.rm = T), mean(R_ar1[,,infos$isHC], na.rm = T),
  sd(R_ar1[,,infos$isSD], na.rm = T), sd(R_ar1[,,infos$isAD], na.rm = T), sd(R_ar1[,,infos$isHC], na.rm = T)),
  dim=c(3,2)
  )

colnames(M)  = c("mean", "SD")
rownames(M) = c("SD", "AD", "HC")
print(M)
```

### Density plots
```{r fig.height=2.5, fig.width=7, message=FALSE, warning=FALSE}
# p1 = ggplot(Rd,     aes(x=R, fill=group)) + geom_histogram(alpha=0.3, position="identity", binwidth = 0.05) +
#   ggtitle("raw") + coord_cartesian(ylim = c(0, 10^5)) 
# p2 = ggplot(Rd_gsr, aes(x=R, fill=group)) + geom_histogram(alpha=0.3, position="identity", binwidth = 0.05) +
#   ggtitle("GSR")
# p3 = ggplot(Rd_ar1, aes(x=R, fill=group)) + geom_histogram(alpha=0.3, position="identity", binwidth = 0.05) +
#   ggtitle("AR1")
# p4 = ggplot(Rd_site, aes(x=R, fill=site)) + geom_histogram(alpha=0.3, position="identity", binwidth = 0.05) +
#   ggtitle("AR1")

p1 = ggplot(Rd,      aes(x=R, fill=group)) + geom_density(alpha=0.5) + ggtitle("raw")
#p2 = ggplot(Rd_gsr,  aes(x=R, fill=group)) + geom_density(alpha=0.3) + ggtitle("GSR")
p3 = ggplot(Rd_ar1,  aes(x=R, fill=group)) + geom_density(alpha=0.5) + ggtitle("GSR + AR1")
#p4 = ggplot(Rd_site, aes(x=R, fill=site))  + geom_density(alpha=0.3) + ggtitle("AR1")

plot_grid(p1, p3, ncol = 2, nrow = 1)
```

## Fisher z-transformation
```{r}
Z = 0.5*(log(1+R_ar1) - log(1-R_ar1))
# Z = 0.5*log((1+R)/(1-R))
# Z = atanh(R)
```

## Load ROIs of temporal regions
```{r Load ROIs}
rois=as.matrix(read.table(file.path(PATH, 'Cradd_tmp_labels.txt'), header = F))
rois=rois[1,]
Nn = length(rois)
```

## Voxel-wise ANOVA
```{r}
# set.seed(1980)
# anova=list()
# anova$groupFvals = array(NA, dim=c(Nn, Nn))
# anova$groupPvals = array(NA, dim=c(Nn, Nn))
# anova$ageFvals = array(NA, dim=c(Nn, Nn))
# anova$agePvals = array(NA, dim=c(Nn, Nn))
# 
# anova$perm.Pvals = array(NA, dim=c(Nn, Nn))
# anova$perm.Stats = array(NA, dim=c(Nn, Nn))
# 
# for (i in 1:Nn) {
#   print(i)
#   for (j in 1:Nn) {
#     if (i > j) {
#       y = Z[rois[i], rois[j], ]
#       idx = infos$included
#       # fit = aov(y[idx] ~ infos$group[idx]) # df=2/52
#       fit = aov(y[idx] ~ infos$group[idx] + infos$age[idx]) # df=2/52
#       # qqnorm(resid(fit))
#       # qqline(resid(fit), col="red")
#       result = summary(fit)
# 
#       anova$groupFvals[i,j] = result[[1]]$`F value`[1]
#       anova$groupPvals[i,j] = result[[1]]$`Pr(>F)`[1]
# 
#       anova$ageFvals[i,j] = result[[1]]$`F value`[2]
#       anova$ageFvals[i,j] = result[[1]]$`Pr(>F)`[2]
# 
#       result2 = permKS(y[idx] ~ infos$group[idx])
# 
#       anova$perm.Stats[i, j] = result2$statistic # df = 2
#       anova$perm.Pvals[i, j] = result2$p.value
#     }
#   }
# }
# 
# save(anova, file = file.path(PATH, 'anova.RData'))
```

## FDR correction
```{r}
load(file.path(PATH, 'anova.RData'))

x=array(NA, dim=c(1,2))
x[1] = sum(anova$groupPvals < 0.05, na.rm = T)
anova$groupPvalsFDR = array(p.adjust(anova$groupPvals, method = "fdr"), dim=c(Nn, Nn))
x[2] = sum(anova$groupPvalsFDR < 0.05, na.rm = T)
colnames(x) = c("No. of sign. edges", "No. of sign. edges (FDR adjusted)")
print(x)

anova$perm.PvalsFDR = array(p.adjust(anova$perm.Pvals, method = "fdr"), dim=c(Nn, Nn))
# sum(anova$perm.PvalsFDR < 0.10, na.rm = T)
```

## Significant edges (Craddock ROI number)
```{r}
idx = which(anova$groupPvalsFDR < 0.05, arr.ind = T)
edges = array(rois[idx], dim=c(nrow(idx),2))
print(edges)
#unique(sort(edges))
```
## Result Table
```{r}
roiLables = read.table(file.path(PATH, 'Cradd_additional_labels.txt'), header = T)
resultsTable = array(NA, dim=c(nrow(edges), 6))

resultsTable[,1:2] = edges
resultsTable[,3:4] = array(roiLables$label[match(edges, roiLables$roinr)], dim=c(nrow(edges),2))
resultsTable[,5] = round(anova$groupFvals[idx], digits = 2)
resultsTable[,6] = round(anova$groupPvalsFDR[idx], digits = 3)
colnames(resultsTable) = c("ROI", "ROI", "Region", "Region", "F-value", "adj. p-value")

# order table based on significance
ord = order(anova$groupFvals[idx], decreasing = T)
print(resultsTable[ord,])
```

## Plot Z scores
```{r fig.height=6, fig.width=7, warning=FALSE}
p = list()

for (i in 1:nrow(edges)) {
  x = Z[edges[i,][1],edges[i,][2],]
  d = data.frame(Z = x[infos$included], group=infos$group[infos$included])
  d$group = factor(d$group, c("HC", "AD", "SD"))
  p[[i]]= ggplot(d, aes(x=group, y=Z, color=group)) + geom_violin(color="gray50") + geom_boxplot(width=0.7) +
    geom_point(shape=1, color="gray80", size=0.5, position = position_jitter(width = 0.2, height = 0)) + 
    # coord_cartesian(ylim = c(-0.5, 1)) +
    theme(plot.title = element_text(size=10, face = "plain"), legend.position="none") +
    ggtitle(sprintf('%d<->%d', edges[i,1], edges[i,2]))
}

plot_grid(plotlist = p, ncol = 4, nrow = 4)
```
## Plot Pearson's R
```{r fig.height=6, fig.width=7, warning=FALSE}
p = list()

for (i in 1:nrow(edges)) {
  x = R[edges[i,][1],edges[i,][2],]
  d = data.frame(r = x[infos$included], group=infos$group[infos$included])
  d$group = factor(d$group, c("HC", "AD", "SD"))
  p[[i]]= ggplot(d, aes(x=group, y=r, color=group)) + geom_violin(color="gray50") + geom_boxplot(width=0.7) +
    geom_point(shape=1, color="gray80", size=1, position = position_jitter(width = 0.2, height = 0)) + 
    #coord_cartesian(ylim = c(-0.5, 1)) +
    theme(plot.title = element_text(size=10, face = "plain"), legend.position="none") +
    ggtitle(sprintf('%d<->%d', edges[i,1], edges[i,2]))
}

plot_grid(plotlist = p, ncol = 4, nrow = 4)
```
### Percentage of neg. correlations across 13 sign. edges and subjects
```{r}
sum(R[edges[,1], edges[,2], infos$included] < 0)/(nrow(edges)*nrow(edges)*sum(infos$included))
```
